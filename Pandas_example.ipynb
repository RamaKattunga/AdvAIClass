{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ba55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for data manipulation and fetching online data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# For fetching stock data; students need to install yfinance\n",
    "# !pip install yfinance  # Uncomment to install if needed\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a337c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1a: Titanic dataset loaded with 891 passengers and 12 columns.\n"
     ]
    }
   ],
   "source": [
    "# --- Section 1: Loading Data from Online Sources ---\n",
    "# Load the Titanic dataset from a GitHub URL, a popular dataset for learning\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df_titanic = pd.read_csv(url)\n",
    "print(\"Step 1a: Titanic dataset loaded with\", df_titanic.shape[0], \"passengers and\", df_titanic.shape[1], \"columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cccde15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yb/m140125x64sd33ncfy_s5vfh0000gp/T/ipykernel_19170/2628451526.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df_stock = yf.download('AAPL', start='2020-01-01', end='2023-01-01', progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1b: Apple stock data loaded with 756 days and 5 columns.\n"
     ]
    }
   ],
   "source": [
    "# Fetch Apple stock data from 2020 to 2023 using yfinance for time series practice\n",
    "df_stock = yf.download('AAPL', start='2020-01-01', end='2023-01-01', progress=False)\n",
    "print(\"Step 1b: Apple stock data loaded with\", df_stock.shape[0], \"days and\", df_stock.shape[1], \"columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3512c32",
   "metadata": {},
   "source": [
    "# Understanding Section 1: Loading Data from Online Sources\n",
    "\n",
    "This section is like opening two treasure chests full of stories! We’re going to grab data from the internet—one about the Titanic passengers and another about Apple stock prices. Let’s see how we bring these treasures into our computer using Pandas to start our learning adventure.\n",
    "\n",
    "- **Why It Matters**: Loading data is the first step for data analysts to explore real-world tales, like who survived the Titanic or how Apple’s stock moved, skills you’ll use in jobs!\n",
    "- **What’s Next**: We’ll check out these treasures and clean them up—stay tuned!\n",
    "\n",
    "# Titanic Dataset Columns Dictionary\n",
    "\n",
    "Below is a simple dictionary representing the columns of the Titanic dataset, like a quick guide to the passenger information we’re exploring!\n",
    "\n",
    "- **Example Dictionary for First Row**:\n",
    "  - `{'PassengerId': 1, 'Survived': 0, 'Pclass': 3, 'Name': 'Braund, Mr. Owen Harris', 'Sex': 'male', 'Age': 22.0, 'SibSp': 1, 'Parch': 0, 'Ticket': 'A/5 21171', 'Fare': 7.2500, 'Cabin': 'NaN', 'Embarked': 'S'}`\n",
    "    - `PassengerId`: A unique number for each passenger (e.g., 1).\n",
    "    - `Survived`: Did they survive? (0 = No, 1 = Yes).\n",
    "    - `Pclass`: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd).\n",
    "    - `Name`: Full name of the passenger (e.g., 'Braund, Mr. Owen Harris').\n",
    "    - `Sex`: Gender of the passenger (e.g., 'male').\n",
    "    - `Age`: Age in years (e.g., 22.0, some missing).\n",
    "    - `SibSp`: Number of siblings or spouses aboard (e.g., 1).\n",
    "    - `Parch`: Number of parents or children aboard (e.g., 0).\n",
    "    - `Ticket`: Ticket number (e.g., 'A/5 21171').\n",
    "    - `Fare`: Ticket price in pounds (e.g., 7.2500).\n",
    "    - `Cabin`: Cabin number (e.g., 'NaN' for missing).\n",
    "    - `Embarked`: Port of embarkation (e.g., 'S' for Southampton).\n",
    "\n",
    "- **What It Means**: \n",
    "  - This dictionary is like a passenger’s ID card! Each column tells us something about them, from their ticket class to whether they survived.\n",
    "  - **Analogy**: Think of it as a checklist a ship captain might use to track everyone on board!\n",
    "- **Why It’s Useful**: As a data scientist, you’ll use these details to predict survival or analyze trends, a skill for jobs like data analysis in history or safety studies!\n",
    "\n",
    "# Loading and Representing Apple Stock Data\n",
    "\n",
    "- **Code**: \n",
    "  - `df_stock = yf.download('AAPL', start='2020-01-01', end='2023-01-01', progress=False)`\n",
    "    - Uses `yfinance` (`yf`) to grab Apple’s stock prices from January 1, 2020, to January 1, 2023, like collecting daily reports from a stock market diary.\n",
    "    - `progress=False` keeps it quiet while loading, avoiding distractions.\n",
    "  - `print(\"Step 1b: Apple stock data loaded with\", df_stock.shape[0], \"days and\", df_stock.shape[1], \"columns.\")`\n",
    "    - Tells us how many days (rows) and details (columns) we got, like counting trading days and their info!\n",
    "\n",
    "- **What It Means**: \n",
    "  - Imagine you’re a treasure hunter collecting a logbook of Apple’s stock prices over three years. This code brings that logbook into our computer to study market trends.\n",
    "  - **Analogy**: It’s like asking a stock market clerk to hand you a daily record book, and we’ll use it to predict future prices!\n",
    "- **Dictionary Representation**: Let’s peek at the data as a mini-dictionary for the first day (2020-01-02):\n",
    "  - Example: \n",
    "    - `{'Date': '2020-01-02', 'Open': 74.06, 'High': 75.15, 'Low': 73.66, 'Close': 75.09, 'Adj Close': 72.82, 'Volume': 135480400}`\n",
    "    - This is like a snapshot of the day: opening price ($74.06), highest ($75.15), lowest ($73.66), closing price ($75.09), adjusted close ($72.82 for dividends), and trading volume (135,480,400 shares).\n",
    "- **Why It’s Useful**: As a data scientist, you could use this to predict stock trends or advise investors, a hot skill in finance jobs!\n",
    "- **What’s Next**: Let’s explore these treasures and clean them up to find hidden gems!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6e986b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2a: First 5 rows of Titanic dataset:\n",
      "   PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked\n",
      "0            1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   7.2500   NaN        S\n",
      "1            2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599  71.2833   C85        C\n",
      "2            3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S\n",
      "3            4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803  53.1000  C123        S\n",
      "4            5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   8.0500   NaN        S\n"
     ]
    }
   ],
   "source": [
    "# --- Section 2: Data Inspection ---\n",
    "# Display the first 5 rows of the Titanic dataset to understand its structure\n",
    "pd.set_option('display.width', 1000)\n",
    "print(\"\\nStep 2a: First 5 rows of Titanic dataset:\")\n",
    "print(df_titanic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84180f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2b: Titanic DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Show DataFrame info (column names, data types, non-null counts)\n",
    "print(\"\\nStep 2b: Titanic DataFrame Info:\")\n",
    "print(df_titanic.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e428d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2c: Titanic Summary Statistics:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics for numerical columns (count, mean, std, etc.)\n",
    "print(\"\\nStep 2c: Titanic Summary Statistics:\")\n",
    "print(df_titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065d4916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2d: Apple Stock Data (First 5 rows):\n",
      "Price           Close       High        Low       Open     Volume\n",
      "Ticker           AAPL       AAPL       AAPL       AAPL       AAPL\n",
      "Date                                                             \n",
      "2020-01-02  72.620834  72.681281  71.373211  71.627084  135480400\n",
      "2020-01-03  71.914818  72.676447  71.689957  71.847118  146322800\n",
      "2020-01-06  72.487846  72.526533  70.783248  71.034709  118387200\n",
      "2020-01-07  72.146942  72.753823  71.926915  72.497529  108872000\n",
      "2020-01-08  73.307510  73.609745  71.849533  71.849533  132079200\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows of stock data to see time series structure\n",
    "print(\"\\nStep 2d: Apple Stock Data (First 5 rows):\")\n",
    "print(df_stock.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6eceff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in Pclass:\n",
      "[3 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Interactive: Ask students to input a column to explore\n",
    "column_to_check = input(\"Step 2e: Enter a Titanic column name to see its unique values (e.g., 'Pclass'): \")\n",
    "print(f\"\\nUnique values in {column_to_check}:\")\n",
    "print(df_titanic[column_to_check].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fec3e30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3a: Missing Values in Titanic Dataset:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Section 3: Data Cleaning ---\n",
    "# Check for missing values in each column of the Titanic dataset\n",
    "print(\"\\nStep 3a: Missing Values in Titanic Dataset:\")\n",
    "print(df_titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16dfa5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3b: Missing 'Age' filled with median: 28.0\n"
     ]
    }
   ],
   "source": [
    "# Fill missing 'Age' values with the median age to preserve data distribution\n",
    "median_age = df_titanic['Age'].median()\n",
    "df_titanic['Age'] = df_titanic['Age'].fillna(median_age)\n",
    "print(\"\\nStep 3b: Missing 'Age' filled with median:\", median_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ae1a0",
   "metadata": {},
   "source": [
    "# Understanding Step 3b: Filling Missing 'Age' Values\n",
    "\n",
    "This step is like filling in the blanks on a family photo album! We’re fixing missing ages in the Titanic dataset to keep our passenger story complete. Let’s break down the code and explore how we do this, plus other ways to fill gaps.\n",
    "\n",
    "## What Are We Doing?\n",
    "- **Definition**: We’re replacing missing age values with a typical age to avoid losing data, helping our analysis stay strong.\n",
    "- **Why It Matters**: As a data scientist, you’ll clean data like this to predict survival or analyze trends, a key skill for jobs in history or safety research!\n",
    "\n",
    "## Breaking Down the Code\n",
    "- **Code**: \n",
    "  - `median_age = df_titanic['Age'].median()`\n",
    "    - Finds the middle age value in the list, like picking the most common age when everyone lines up from youngest to oldest.\n",
    "  - `df_titanic['Age'] = df_titanic['Age'].fillna(median_age)`\n",
    "    - Fills all the blank age spots with that middle age, like pasting a photo in every empty album slot.\n",
    "  - `print(\"\\nStep 3b: Missing 'Age' filled with median:\", median_age)`\n",
    "    - Tells us the middle age used, so we know what filled the gaps!\n",
    "\n",
    "- **What It Means**: \n",
    "  - Imagine you’re organizing a class photo, but some kids forgot their ages. You ask the group, find the average age (say, 28), and write that for the missing ones. This keeps the album full and fair!\n",
    "  - **Analogy**: It’s like a teacher guessing a student’s age based on the class average when their record is lost!\n",
    "- **Why It’s Useful**: Using the median keeps the age spread natural, helping us predict who survived without skewing the story.\n",
    "\n",
    "## Other Filling Techniques\n",
    "- **Mean Filling**: Replaces missing ages with the average age (e.g., 29.7 if that’s the mean). Like asking the whole class for their age total and dividing—simple but can be pulled by extreme values (e.g., a 70-year-old).\n",
    "- **Mode Filling**: Uses the most common age (e.g., 24 if most passengers are that age). Like picking the age most kids share—great for skewed data but might over-repeat.\n",
    "- **Forward Fill**: Copies the age from the passenger before (e.g., 25 for the next if the last was 25). Like filling a missing photo with the one before it—works for ordered data like time logs.\n",
    "- **Backward Fill**: Copies the age from the passenger after. Like using the next photo’s age—also for ordered data.\n",
    "- **Interpolation**: Guesses ages based on a smooth line between known ages. Like drawing a curve to fill gaps in a growth chart—fancy but needs a pattern.\n",
    "- **Why Choose?**: The median is solid for the Titanic because ages vary a lot. You’d pick based on your data as a data analyst!\n",
    "\n",
    "## What’s Next?\n",
    "- We’ll clean up more missing spots and get ready to find patterns. Keep exploring this passenger story!\n",
    "- *Note*: This dataset has historical gaps, which we’ll handle fairly in Week 4. For now, enjoy filling these blanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f32e7edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3c: Missing 'Embarked' filled with mode: S\n"
     ]
    }
   ],
   "source": [
    "# Fill missing 'Embarked' with the most common port (mode) to maintain consistency\n",
    "most_common_embarked = df_titanic['Embarked'].mode()[0]\n",
    "df_titanic['Embarked'] = df_titanic['Embarked'].fillna(most_common_embarked)\n",
    "print(\"Step 3c: Missing 'Embarked' filled with mode:\", most_common_embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "653dc283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3d: 'Cabin' column dropped due to many missing values.\n"
     ]
    }
   ],
   "source": [
    "# Drop 'Cabin' column due to excessive missing values, reducing noise\n",
    "df_titanic = df_titanic.drop('Cabin', axis=1)\n",
    "print(\"\\nStep 3d: 'Cabin' column dropped due to many missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58954c75",
   "metadata": {},
   "source": [
    "# Understanding Step 3d: Dropping the 'Cabin' Column\n",
    "\n",
    "This step is like cleaning up a messy drawer! We’re getting rid of the 'Cabin' column in the Titanic dataset because it has too many missing entries, which can confuse our story. Let’s break down the code to see how we tidy things up.\n",
    "\n",
    "## What Are We Doing?\n",
    "- **Definition**: We’re removing the 'Cabin' column because it has lots of blank spots, helping our data stay clear and useful.\n",
    "- **Why It Matters**: As a data scientist, you’ll clean data like this to focus on what helps predict outcomes, like survival rates, a key skill for jobs in research or safety analysis!\n",
    "\n",
    "## Breaking Down the Code\n",
    "- **Code**: \n",
    "  - `df_titanic = df_titanic.drop('Cabin', axis=1)`\n",
    "    - Tells Pandas to throw out the 'Cabin' column from our table (`df_titanic`).\n",
    "    - `axis=1` means we’re dropping a column (not a row), like pulling out a cluttered drawer section.\n",
    "  - `print(\"\\nStep 3d: 'Cabin' column dropped due to many missing values.\")`\n",
    "    - Lets us know the messy column is gone, like a note saying the drawer is cleaner!\n",
    "\n",
    "- **What It Means**: \n",
    "  - Imagine you’re sorting a passenger list, but the 'Cabin' section has too many blank spots because cabins weren’t recorded. We toss it out to avoid guessing, keeping our focus on solid info like age or fare.\n",
    "  - **Analogy**: It’s like a librarian throwing away a torn page with missing names to keep the book readable!\n",
    "- **Why It’s Useful**: Dropping noisy data helps our model predict better, like ignoring bad clues in a mystery game.\n",
    "\n",
    "## What’s Next?\n",
    "- We’ll check if any other gaps need fixing and get ready to find patterns. Keep exploring this cleaner dataset!\n",
    "- *Note*: This dataset has historical gaps, which we’ll handle fairly in Week 4. For now, enjoy tidying up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b93ab19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3e: Missing Values After Cleaning:\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify no missing values remain after cleaning\n",
    "print(\"Step 3e: Missing Values After Cleaning:\")\n",
    "print(df_titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4a11973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3f: Number of Duplicate Rows: 0\n",
      "Step 3g: Duplicate rows removed. New shape: (891, 11)\n"
     ]
    }
   ],
   "source": [
    "# Check and remove duplicate rows in the Titanic dataset\n",
    "print(\"\\nStep 3f: Number of Duplicate Rows:\", df_titanic.duplicated().sum())\n",
    "df_titanic = df_titanic.drop_duplicates()\n",
    "print(\"Step 3g: Duplicate rows removed. New shape:\", df_titanic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "513f00e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3h: Missing values in stock data filled with forward fill.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yb/m140125x64sd33ncfy_s5vfh0000gp/T/ipykernel_19170/1574168845.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_stock = df_stock.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Clean stock data: Handle any missing values with forward fill\n",
    "df_stock = df_stock.fillna(method='ffill')\n",
    "print(\"\\nStep 3h: Missing values in stock data filled with forward fill.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4120930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4a: Passengers older than 30 (first 5):\n",
      "    PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch    Ticket     Fare Embarked\n",
      "1             2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0  PC 17599  71.2833        C\n",
      "3             4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0    113803  53.1000        S\n",
      "4             5         0       3                           Allen, Mr. William Henry    male  35.0      0      0    373450   8.0500        S\n",
      "6             7         0       1                            McCarthy, Mr. Timothy J    male  54.0      0      0     17463  51.8625        S\n",
      "11           12         1       1                           Bonnell, Miss. Elizabeth  female  58.0      0      0    113783  26.5500        S\n"
     ]
    }
   ],
   "source": [
    "# --- Section 4: Data Transformation ---\n",
    "# Filter passengers older than 30 to focus on a specific group\n",
    "older_than_30 = df_titanic[df_titanic['Age'] > 30]\n",
    "print(\"\\nStep 4a: Passengers older than 30 (first 5):\")\n",
    "print(older_than_30.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b1741fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4b: Top 5 passengers by fare:\n",
      "                                   Name      Fare\n",
      "258                    Ward, Miss. Anna  512.3292\n",
      "737              Lesurer, Mr. Gustave J  512.3292\n",
      "679  Cardeza, Mr. Thomas Drake Martinez  512.3292\n",
      "88           Fortune, Miss. Mabel Helen  263.0000\n",
      "27       Fortune, Mr. Charles Alexander  263.0000\n"
     ]
    }
   ],
   "source": [
    "# Sort passengers by 'Fare' in descending order to identify high spenders\n",
    "sorted_by_fare = df_titanic.sort_values(by='Fare', ascending=False)\n",
    "print(\"\\nStep 4b: Top 5 passengers by fare:\")\n",
    "print(sorted_by_fare[['Name', 'Fare']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72f71e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4c: Mean Fare by Pclass:\n",
      "Pclass\n",
      "1    84.154687\n",
      "2    20.662183\n",
      "3    13.675550\n",
      "Name: Fare, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Pclass' and calculate mean 'Fare' to analyze class-based pricing\n",
    "mean_fare_by_class = df_titanic.groupby('Pclass')['Fare'].mean()\n",
    "print(\"\\nStep 4c: Mean Fare by Pclass:\")\n",
    "print(mean_fare_by_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6443a149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Fare by Sex:\n",
      "Sex\n",
      "female    44.479818\n",
      "male      25.523893\n",
      "Name: Fare, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Interactive: Group by a column chosen by students\n",
    "group_by_col = input(\"Step 4d: Enter a column to group by (e.g., 'Sex'): \")\n",
    "if group_by_col in df_titanic.columns:\n",
    "    group_result = df_titanic.groupby(group_by_col)['Fare'].mean()\n",
    "    print(f\"\\nMean Fare by {group_by_col}:\")\n",
    "    print(group_result)\n",
    "else:\n",
    "    print(\"Column not found. Try 'Sex', 'Pclass', or 'Embarked'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a0e214e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5a: Added 'FamilySize' feature. First 5 rows:\n",
      "   SibSp  Parch  FamilySize\n",
      "0      1      0           2\n",
      "1      1      0           2\n",
      "2      0      0           1\n",
      "3      1      0           2\n",
      "4      0      0           1\n"
     ]
    }
   ],
   "source": [
    "# --- Section 5: Feature Engineering ---\n",
    "# Create 'FamilySize' feature by summing 'SibSp', 'Parch', and 1 (self)\n",
    "df_titanic['FamilySize'] = df_titanic['SibSp'] + df_titanic['Parch'] + 1\n",
    "print(\"\\nStep 5a: Added 'FamilySize' feature. First 5 rows:\")\n",
    "print(df_titanic[['SibSp', 'Parch', 'FamilySize']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ddb27",
   "metadata": {},
   "source": [
    "# Understanding Section 5: Feature Engineering\n",
    "\n",
    "This section is like being a chef who mixes new ingredients to make a tastier dish! We’re creating a new data piece called 'FamilySize' to help us understand the Titanic passengers better. Let’s break down the code and learn what feature engineering is all about.\n",
    "\n",
    "## What is Feature Engineering?\n",
    "- **Definition**: Feature engineering is when we make new data columns from existing ones to give our model better clues for predicting things, like who survived.\n",
    "- **Simple Analogy**: Imagine you’re baking a cake. You have flour and sugar, but you mix them into batter to make it yummier. Feature engineering is like that—it combines raw data (like family members) into a new, helpful ingredient!\n",
    "- **Why It Matters**: As a data scientist, you’ll create features like this to improve predictions, a key skill for jobs in research or business!\n",
    "\n",
    "## Breaking Down the Code\n",
    "- **Code**: \n",
    "  - `# Create 'FamilySize' feature by summing 'SibSp', 'Parch', and 1 (self)`\n",
    "    - Tells us we’re making a new column called 'FamilySize' by adding up family details.\n",
    "  - `df_titanic['FamilySize'] = df_titanic['SibSp'] + df_titanic['Parch'] + 1`\n",
    "    - Adds `SibSp` (siblings/spouses), `Parch` (parents/children), and 1 (the passenger themselves) for each row.\n",
    "    - Like counting everyone in a family: siblings, parents, and you!\n",
    "  - `print(\"\\nStep 5a: Added 'FamilySize' feature. First 5 rows:\")`\n",
    "    - Lets us know the new feature is ready and shows the first five examples.\n",
    "  - `print(df_titanic[['SibSp', 'Parch', 'FamilySize']].head())`\n",
    "    - Displays a table with `SibSp`, `Parch`, and `FamilySize` for the first five passengers, like a family roll call!\n",
    "\n",
    "- **What It Means**: \n",
    "  - Imagine you’re tracking a passenger’s family on the Titanic. If they have 1 sibling and 0 parents, plus themselves (1), their 'FamilySize' is 2. This new number helps us see if bigger families survived differently.\n",
    "  - **Analogy**: It’s like a teacher adding up students, their siblings, and parents to figure out class family sizes for a group project!\n",
    "- **Why It’s Useful**: A bigger 'FamilySize' might mean more support or chaos, which could affect survival. This new clue helps our model guess better!\n",
    "\n",
    "## What’s Next?\n",
    "- We’ll create more helpful features and get ready to predict survival. Keep cooking up these data ingredients!\n",
    "- *Note*: This dataset has historical gaps, which we’ll handle fairly in Week 4. For now, enjoy building new features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a8af01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5b: One-hot encoded 'Sex' and 'Embarked'. New columns:\n",
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'FamilySize', 'Sex_male', 'Embarked_Q', 'Embarked_S']\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode 'Sex' and 'Embarked' for ML model compatibility\n",
    "df_titanic = pd.get_dummies(df_titanic, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "print(\"\\nStep 5b: One-hot encoded 'Sex' and 'Embarked'. New columns:\")\n",
    "print(list(df_titanic.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2e6d8d",
   "metadata": {},
   "source": [
    "# Understanding Step 5b: One-Hot Encoding 'Sex' and 'Embarked'\n",
    "\n",
    "This step is like turning a messy name tag into clear yes-or-no buttons! We’re transforming 'Sex' and 'Embarked' into a format our machine learning model can understand easily. Let’s break down the code, learn what one-hot encoding is, and practice remembering it with a fun trick.\n",
    "\n",
    "## What is One-Hot Encoding?\n",
    "- **Definition**: One-hot encoding changes categories (like 'male' or 'female') into separate yes/no columns (e.g., 1 for yes, 0 for no) so our model can use them to predict things, like who survived the Titanic.\n",
    "- **Simple Analogy**: Imagine you’re sorting friends into teams by favorite color—red, blue, or green. Instead of writing “blue,” you give each friend a badge: “IsRed? 0,” “IsBlue? 1,” “IsGreen? 0.” This way, the computer sees clear choices, not words!\n",
    "- **Memory Trick**: Think “One-Hot = One Yes!”—each person or data point gets one “yes” (1) and the rest are “no” (0), like flipping a single light switch on in a row of switches.\n",
    "- **Why It Matters**: As a data scientist, you’ll use this to prepare data for predictions, a key skill for jobs in marketing or safety analysis!\n",
    "\n",
    "## Breaking Down the Code\n",
    "- **Code**: \n",
    "  - `# One-hot encode 'Sex' and 'Embarked' for ML model compatibility`\n",
    "    - Tells us we’re making 'Sex' (male/female) and 'Embarked' (port names) ready for our model.\n",
    "  - `df_titanic = pd.get_dummies(df_titanic, columns=['Sex', 'Embarked'], drop_first=True)`\n",
    "    - Uses Pandas (`pd.get_dummies`) to turn 'Sex' and 'Embarked' into new columns.\n",
    "    - `columns=['Sex', 'Embarked']` picks these two to change.\n",
    "    - `drop_first=True` skips the first category (e.g., 'female' or 'C') to avoid repeats, like not needing a “Not Red” badge if we have “Red.”\n",
    "  - `print(\"\\nStep 5b: One-hot encoded 'Sex' and 'Embarked'. New columns:\")`\n",
    "    - Lets us know the change is done and shows the new column names.\n",
    "  - `print(list(df_titanic.columns))`\n",
    "    - Lists all columns now, including the new ones, like checking our updated name tag collection!\n",
    "\n",
    "- **What It Means**: \n",
    "  - Before: 'Sex' might be 'male' or 'female,' and 'Embarked' might be 'S,' 'C,' or 'Q' (ports). After, we get columns like 'Sex_male' (1 if male, 0 if female) and 'Embarked_Q' (1 if Queenstown, 0 if not).\n",
    "  - **Analogy**: It’s like giving each passenger a set of light switches—one for “male” and one for “Queenstown”—turning on only the right ones to show who they are!\n",
    "- **Memory Trick Practice**: Say “One-Hot = One Yes!” while imagining switches. Flip one on (e.g., 'Sex_male' = 1) and others off (e.g., 'Sex_female' = 0) for each passenger to build that muscle memory.\n",
    "- **Why It’s Useful**: This format helps our model understand categories without mixing them up, improving survival predictions!\n",
    "\n",
    "## What’s Next?\n",
    "- We’ll create more features to make our model even smarter. Keep flipping those switches to learn more!\n",
    "- *Note*: This dataset has historical gaps, which we’ll handle fairly in Week 4. For now, enjoy turning data into clear signals!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c345c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5c: Added 'AgeGroup' feature. First 5 rows:\n",
      "    Age     AgeGroup\n",
      "0  22.0  Young Adult\n",
      "1  38.0        Adult\n",
      "2  26.0  Young Adult\n",
      "3  35.0  Young Adult\n",
      "4  35.0  Young Adult\n"
     ]
    }
   ],
   "source": [
    "# Bin 'Age' into categories for better feature representation\n",
    "bins = [0, 12, 18, 35, 60, 100]\n",
    "labels = ['Child', 'Teen', 'Young Adult', 'Adult', 'Senior']\n",
    "df_titanic['AgeGroup'] = pd.cut(df_titanic['Age'], bins=bins, labels=labels)\n",
    "print(\"\\nStep 5c: Added 'AgeGroup' feature. First 5 rows:\")\n",
    "print(df_titanic[['Age', 'AgeGroup']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01361e3",
   "metadata": {},
   "source": [
    "# Understanding Step 5c: Binning 'Age' into Categories\n",
    "\n",
    "This step is like sorting toys into different boxes by size! We’re grouping passenger ages into categories like 'Child' or 'Adult' to make our Titanic data easier for the model to understand. Let’s break down the code, learn what binning is, and practice remembering it with a fun trick.\n",
    "\n",
    "## What is Binning?\n",
    "- **Definition**: Binning puts ages into labeled groups (e.g., 'Teen', 'Adult') instead of using exact numbers, helping our model spot patterns better.\n",
    "- **Simple Analogy**: Imagine you’re organizing a toy chest. You put small toys in a 'Tiny' box, medium ones in a 'Medium' box, and big ones in a 'Large' box. Binning is like that—it sorts ages into neat groups!\n",
    "- **Memory Trick**: Think “Bin = Box!”—each bin is a box where we drop ages, and we label the box to remember who fits where. Say “Bin = Box!” a few times to lock it in!\n",
    "- **Why It Matters**: As a data scientist, you’ll use binning to simplify data for predictions, a key skill for jobs in marketing or safety studies!\n",
    "\n",
    "## Breaking Down the Code\n",
    "- **Code**: \n",
    "  - `# Bin 'Age' into categories for better feature representation`\n",
    "    - Tells us we’re grouping 'Age' to help our model see the big picture.\n",
    "  - `bins = [0, 12, 18, 35, 60, 100]`\n",
    "    - Sets up age cutoffs: 0–12, 12–18, 18–35, 35–60, 60–100, like drawing lines on a ruler.\n",
    "  - `labels = ['Child', 'Teen', 'Young Adult', 'Adult', 'Senior']`\n",
    "    - Names each group, like labeling our toy boxes with fun tags!\n",
    "  - `df_titanic['AgeGroup'] = pd.cut(df_titanic['Age'], bins=bins, labels=labels)`\n",
    "    - Uses Pandas (`pd.cut`) to sort ages into these groups and adds a new column called 'AgeGroup'.\n",
    "    - Like putting each passenger’s age into the right box based on the ruler lines.\n",
    "  - `print(\"\\nStep 5c: Added 'AgeGroup' feature. First 5 rows:\")`\n",
    "    - Lets us know the new group column is ready and shows the first five examples.\n",
    "  - `print(df_titanic[['Age', 'AgeGroup']].head())`\n",
    "    - Displays a table with 'Age' and 'AgeGroup' for the first five passengers, like peeking into our sorted boxes!\n",
    "\n",
    "- **What It Means**: \n",
    "  - Before: Ages were numbers like 22 or 35. Now, a 22-year-old goes into 'Young Adult' and a 40-year-old into 'Adult'.\n",
    "  - **Analogy**: It’s like a teacher sorting students into age teams—'Child' for under 12, 'Teen' for 12–18—making it easier to plan activities!\n",
    "- **Memory Trick Practice**: Say “Bin = Box!” and imagine dropping ages into labeled boxes. Check the output to see who’s in each team to build that muscle memory.\n",
    "- **Why It’s Useful**: Grouping ages helps our model see if kids or seniors survived differently, improving our survival predictions!\n",
    "\n",
    "## What’s Next?\n",
    "- We’ll create more grouped features to make our model even smarter. Keep sorting those boxes to learn more!\n",
    "- *Note*: This dataset has historical gaps, which we’ll handle fairly in Week 4. For now, enjoy organizing these ages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "810ed527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled Fare added. First 5 rows:\n",
      "      Fare  Fare_scaled\n",
      "0   7.2500     0.014151\n",
      "1  71.2833     0.139136\n",
      "2   7.9250     0.015469\n",
      "3  53.1000     0.103644\n",
      "4   8.0500     0.015713\n"
     ]
    }
   ],
   "source": [
    "# Interactive: Ask students to suggest a feature to scale\n",
    "feature_to_scale = input(\"Step 5d: Enter a numerical feature to scale (e.g., 'Fare'): \")\n",
    "if feature_to_scale in df_titanic.select_dtypes(include=[np.number]).columns:\n",
    "    df_titanic[feature_to_scale + '_scaled'] = (df_titanic[feature_to_scale] - df_titanic[feature_to_scale].min()) / (df_titanic[feature_to_scale].max() - df_titanic[feature_to_scale].min())\n",
    "    print(f\"\\nScaled {feature_to_scale} added. First 5 rows:\")\n",
    "    print(df_titanic[[feature_to_scale, feature_to_scale + '_scaled']].head())\n",
    "else:\n",
    "    print(\"Please enter a valid numerical column like 'Fare' or 'Age'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c171405",
   "metadata": {},
   "source": [
    "# Understanding Step 5d: Scaling a Numerical Feature\n",
    "\n",
    "This step is like adjusting the volume on a radio so all songs sound balanced! We’re scaling a number like 'Fare' to make our Titanic data fair for the model. Let’s break down the code, learn why, what, and when to scale, and check the results with a fun trick to remember it.\n",
    "\n",
    "## What is Scaling?\n",
    "- **Definition**: Scaling changes big or small numbers (e.g., 'Fare' from $0 to $500) into a range like 0 to 1, so our model treats them equally.\n",
    "- **Why to Apply**: Models like our future regression need all numbers on the same scale. If one feature (e.g., 'Fare' at $500) is huge and another (e.g., 'Age' at 30) is small, the big one might drown out the small one!\n",
    "  - **Analogy**: It’s like mixing ingredients for a cake. If you add 500g of sugar and 30g of salt without adjusting, the sugar overshadows the salt. Scaling balances them, like using teaspoons for both!\n",
    "- **What It Does**: Turns raw numbers into a 0-to-1 scale where the smallest value becomes 0 and the largest becomes 1.\n",
    "- **When to Apply**: Use scaling when numbers vary widely (e.g., 'Fare' vs. 'Age') and you’re using models that care about size, like regression or machine learning tools we’ll meet soon.\n",
    "  - **Analogy**: Scale when you’re comparing apples and watermelons by weight—turn them into a fair size range so the comparison makes sense!\n",
    "- **Memory Trick**: Think “Scale = Balance!”—imagine a seesaw leveling out big and small weights. Say “Scale = Balance!” a few times to lock it in!\n",
    "- **Why It Matters**: As a data scientist, you’ll scale data to improve predictions, a key skill for jobs in finance or marketing!\n",
    "\n",
    "## Breaking Down the Code\n",
    "- **Code**: \n",
    "  - `# Interactive: Ask students to suggest a feature to scale`\n",
    "    - Invites you to pick a number column to adjust, like choosing which ingredient to balance.\n",
    "  - `feature_to_scale = input(\"Step 5d: Enter a numerical feature to scale (e.g., 'Fare'): \")`\n",
    "    - Asks you to type a column name, like 'Fare' or 'Age', to work on.\n",
    "  - `if feature_to_scale in df_titanic.select_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f99cafbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 6a: Stock data index converted to datetime.\n"
     ]
    }
   ],
   "source": [
    "# --- Section 6: Time Series Manipulation ---\n",
    "# Ensure stock data index is datetime for time series operations\n",
    "df_stock.index = pd.to_datetime(df_stock.index)\n",
    "print(\"\\nStep 6a: Stock data index converted to datetime.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d03d868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 6b: Monthly Average Closing Price (first 5):\n",
      "Ticker           AAPL\n",
      "Date                 \n",
      "2020-01-31  75.417396\n",
      "2020-02-29  75.401414\n",
      "2020-03-31  63.606265\n",
      "2020-04-30  66.015845\n",
      "2020-05-31  75.283144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yb/m140125x64sd33ncfy_s5vfh0000gp/T/ipykernel_19170/1991924989.py:2: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_close = df_stock['Close'].resample('M').mean()\n"
     ]
    }
   ],
   "source": [
    "# Resample stock data to monthly frequency, calculating mean closing price\n",
    "monthly_close = df_stock['Close'].resample('M').mean()\n",
    "print(\"\\nStep 6b: Monthly Average Closing Price (first 5):\")\n",
    "print(monthly_close.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18b9f9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 6c: 50-Day Moving Average (first 5):\n",
      "Price           Close MA50\n",
      "Ticker           AAPL     \n",
      "Date                      \n",
      "2020-01-02  72.620834  NaN\n",
      "2020-01-03  71.914818  NaN\n",
      "2020-01-06  72.487846  NaN\n",
      "2020-01-07  72.146942  NaN\n",
      "2020-01-08  73.307510  NaN\n"
     ]
    }
   ],
   "source": [
    "# Calculate 50-day moving average to smooth stock price trends\n",
    "df_stock['MA50'] = df_stock['Close'].rolling(window=50).mean()\n",
    "print(\"\\nStep 6c: 50-Day Moving Average (first 5):\")\n",
    "print(df_stock[['Close', 'MA50']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcf5161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30-Day Moving Average (first 5):\n",
      "Price           Close MA30\n",
      "Ticker           AAPL     \n",
      "Date                      \n",
      "2020-01-02  72.620834  NaN\n",
      "2020-01-03  71.914818  NaN\n",
      "2020-01-06  72.487846  NaN\n",
      "2020-01-07  72.146942  NaN\n",
      "2020-01-08  73.307510  NaN\n"
     ]
    }
   ],
   "source": [
    "# Interactive: Ask for a window size for moving average\n",
    "window_size = int(input(\"Step 6d: Enter a window size for moving average (e.g., 30): \"))\n",
    "df_stock['MA' + str(window_size)] = df_stock['Close'].rolling(window=window_size).mean()\n",
    "print(f\"\\n{window_size}-Day Moving Average (first 5):\")\n",
    "print(df_stock[['Close', 'MA' + str(window_size)]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed895e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 7a: Added 'FareCategory' feature. First 5 rows:\n",
      "      Fare FareCategory\n",
      "0   7.2500        Cheap\n",
      "1  71.2833    Expensive\n",
      "2   7.9250        Cheap\n",
      "3  53.1000    Expensive\n",
      "4   8.0500        Cheap\n"
     ]
    }
   ],
   "source": [
    "# --- Section 7: Applying Custom Functions ---\n",
    "# Define a function to categorize fares into 'Cheap', 'Moderate', 'Expensive'\n",
    "def fare_category(fare):\n",
    "    if fare < 10:\n",
    "        return 'Cheap'\n",
    "    elif fare < 50:\n",
    "        return 'Moderate'\n",
    "    else:\n",
    "        return 'Expensive'\n",
    "    \n",
    "    # Apply the fare_category function to create a new feature\n",
    "df_titanic['FareCategory'] = df_titanic['Fare'].apply(fare_category)\n",
    "print(\"\\nStep 7a: Added 'FareCategory' feature. First 5 rows:\")\n",
    "print(df_titanic[['Fare', 'FareCategory']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e890bb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom categories for Age:\n",
      "    Age Age_Custom\n",
      "0  22.0     Middle\n",
      "1  38.0     Middle\n",
      "2  26.0     Middle\n",
      "3  35.0     Middle\n",
      "4  35.0     Middle\n"
     ]
    }
   ],
   "source": [
    "# Interactive: Ask students to define a custom category function\n",
    "def custom_category(value, threshold1, threshold2, labels):\n",
    "    if value < threshold1:\n",
    "        return labels[0]\n",
    "    elif value < threshold2:\n",
    "        return labels[1]\n",
    "    else:\n",
    "        return labels[2]\n",
    "\n",
    "col_to_categorize = input(\"Step 7b: Enter a numerical column to categorize (e.g., 'Age'): \")\n",
    "if col_to_categorize in df_titanic.select_dtypes(include=[np.number]).columns:\n",
    "    thresh1 = float(input(\"Enter first threshold (e.g., 20): \"))\n",
    "    thresh2 = float(input(\"Enter second threshold (e.g., 40): \"))\n",
    "    custom_labels = input(\"Enter three labels separated by commas (e.g., 'Young,Middle,Old'): \").split(',')\n",
    "    df_titanic[col_to_categorize + '_Custom'] = df_titanic[col_to_categorize].apply(custom_category, args=(thresh1, thresh2, custom_labels))\n",
    "    print(f\"\\nCustom categories for {col_to_categorize}:\")\n",
    "    print(df_titanic[[col_to_categorize, col_to_categorize + '_Custom']].head())\n",
    "else:\n",
    "    print(\"Please enter a valid numerical column like 'Age' or 'Fare'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fee347d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 8a: MultiIndex DataFrame (first 5):\n",
      "                 PassengerId  Survived                                               Name   Age  SibSp  Parch            Ticket     Fare  FamilySize  Embarked_Q  Embarked_S     AgeGroup  Fare_scaled FareCategory Age_Custom\n",
      "Pclass Sex_male                                                                                                                                                                                                               \n",
      "3      True                1         0                            Braund, Mr. Owen Harris  22.0      1      0         A/5 21171   7.2500           2       False        True  Young Adult     0.014151        Cheap     Middle\n",
      "1      False               2         1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0          PC 17599  71.2833           2       False       False        Adult     0.139136    Expensive     Middle\n",
      "3      False               3         1                             Heikkinen, Miss. Laina  26.0      0      0  STON/O2. 3101282   7.9250           1       False        True  Young Adult     0.015469        Cheap     Middle\n",
      "1      False               4         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0            113803  53.1000           2       False        True  Young Adult     0.103644    Expensive     Middle\n",
      "3      True                5         0                           Allen, Mr. William Henry  35.0      0      0            373450   8.0500           1       False        True  Young Adult     0.015713        Cheap     Middle\n"
     ]
    }
   ],
   "source": [
    "# --- Section 8: Advanced Pandas Operations ---\n",
    "# Create a MultiIndex DataFrame by setting 'Pclass' and 'Sex_male' as indices\n",
    "df_titanic_multi = df_titanic.set_index(['Pclass', 'Sex_male'])\n",
    "print(\"\\nStep 8a: MultiIndex DataFrame (first 5):\")\n",
    "print(df_titanic_multi.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9472b111",
   "metadata": {},
   "source": [
    "# Understanding Step 8a: Creating a MultiIndex DataFrame\n",
    "\n",
    "This step is like organizing a big family reunion chart with two labels! We’re setting up the Titanic data with 'Pclass' and 'Sex_male' as special markers to group passengers in a fancy way. Let’s break down the code, learn what a MultiIndex is, and practice remembering it with a fun trick.\n",
    "\n",
    "## What is a MultiIndex DataFrame?\n",
    "- **Definition**: A MultiIndex DataFrame uses two or more columns (like 'Pclass' and 'Sex_male') as labels to organize data into layers, making it easier to find specific groups.\n",
    "- **Simple Analogy**: Imagine you’re sorting a big box of family photos. You label them by “Family Name” and “Birthday Year” to quickly find, say, “Smith 1990” photos. A MultiIndex is like that—it stacks labels to sort data!\n",
    "- **Memory Trick**: Think “Multi = Many Labels!”—picture stacking two name tags (e.g., 'Pclass' and 'Sex_male') on each passenger to find them fast. Say “Multi = Many Labels!” a few times to lock it in!\n",
    "- **Why It Matters**: As a data scientist, you’ll use MultiIndex to analyze groups (e.g., survival by class and gender), a key skill for jobs in research or business!\n",
    "\n",
    "## Breaking Down the Code\n",
    "- **Code**: \n",
    "  - `# Create a MultiIndex DataFrame by setting 'Pclass' and 'Sex_male' as indices`\n",
    "    - Tells us we’re making a special table with 'Pclass' (ticket class) and 'Sex_male' (1 for male, 0 for female) as the main organizers.\n",
    "  - `df_titanic_multi = df_titanic.set_index(['Pclass', 'Sex_male'])`\n",
    "    - Uses Pandas (`set_index`) to turn 'Pclass' and 'Sex_male' into layered labels for our table (`df_titanic_multi`).\n",
    "    - Like pinning two labels on each photo: one for class (1, 2, 3) and one for gender (male or not).\n",
    "  - `print(\"\\nStep 8a: MultiIndex DataFrame (first 5):\")`\n",
    "    - Lets us know the new table is ready and shows the first five examples.\n",
    "  - `print(df_titanic_multi.head())`\n",
    "    - Displays the first five rows of the new table, like peeking at the top of our organized photo box!\n",
    "\n",
    "- **What It Means**: \n",
    "  - Before: Data was a flat list. Now, it’s grouped by 'Pclass' (e.g., 3) and 'Sex_male' (e.g., 1), so we can quickly find, say, all third-class males.\n",
    "  - **Analogy**: It’s like a librarian filing books by “Genre” and “Author” on the shelf, making it easy to grab a mystery by Agatha Christie!\n",
    "- **Memory Trick Practice**: Say “Multi = Many Labels!” and imagine stacking 'Pclass' and 'Sex_male' tags on each passenger. Check the output to see the new layout and build that muscle memory.\n",
    "- **Why It’s Useful**: This helps our model see patterns, like if third-class males survived less, improving our predictions!\n",
    "\n",
    "## What’s Next?\n",
    "- We’ll explore more advanced ways to organize data and get ready for predictions. Keep stacking those labels to learn more!\n",
    "- *Note*: This dataset has historical gaps, which we’ll handle fairly in Week 4. For now, enjoy organizing with MultiIndex!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca31d857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 8b: Log of Fare (first 5):\n",
      "      Fare   LogFare\n",
      "0   7.2500  2.110213\n",
      "1  71.2833  4.280593\n",
      "2   7.9250  2.188856\n",
      "3  53.1000  3.990834\n",
      "4   8.0500  2.202765\n"
     ]
    }
   ],
   "source": [
    "# Use vectorized operation to calculate log of 'Fare' (adding 1 to avoid log(0))\n",
    "df_titanic['LogFare'] = np.log1p(df_titanic['Fare'])\n",
    "print(\"\\nStep 8b: Log of Fare (first 5):\")\n",
    "print(df_titanic[['Fare', 'LogFare']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a72d1",
   "metadata": {},
   "source": [
    "# Understanding Step 8b: Using a Vectorized Log Operation\n",
    "\n",
    "This step is like turning a loud shout into a soft whisper to make it easier to listen! We’re changing the 'Fare' prices in the Titanic dataset into a smoother form using a log trick, and we’ll do it super fast for all passengers at once. Let’s break it down, learn why and when to use this, and make it fun to remember—even without math skills!\n",
    "\n",
    "## What is a Vectorized Log Operation?\n",
    "- **Definition**: A vectorized log operation takes big or small numbers (like ticket prices) and turns them into a gentler scale using a “log” (short for logarithm), doing it for all data at once super quickly.\n",
    "- **Why to Use**: \n",
    "  - **Why**: Big numbers (e.g., $500 fares) can overpower small ones (e.g., $7 fares) in predictions, making our model unfair. Logging shrinks the big ones more, balancing them out.\n",
    "  - **Analogy**: It’s like turning up the volume on a quiet voice and turning down a loud shout so everyone can be heard equally at a party!\n",
    "- **What It Does**: Changes numbers so the differences feel smaller. For example, $7 becomes a tiny number, and $500 becomes a bigger but manageable number, all in one go.\n",
    "- **When to Use**: \n",
    "  - Use this when numbers vary a lot (e.g., fares from $0 to $500) and you’re predicting something, like survival or house prices, with a model that likes balanced data.\n",
    "  - **Analogy**: Use it when you’re comparing a tiny puppy’s bark with a big dog’s howl—log it to make both sounds fit on the same listening level!\n",
    "- **Memory Trick**: Think “Log = Level!”—imagine a volume knob leveling out loud and quiet sounds. Say “Log = Level!” a few times to get it stuck in your head, no math needed!\n",
    "- **Why It Matters**: As a data scientist, you’ll use this to make data friendly for predictions, a key skill for jobs in finance or travel analysis!\n",
    "\n",
    "## Breaking Down the Code\n",
    "- **Code**: \n",
    "  - `# Use vectorized operation to calculate log of 'Fare' (adding 1 to avoid log(0))`\n",
    "    - Tells us we’re smoothing 'Fare' prices with a log, and adding 1 stops errors if a fare is $0.\n",
    "  - `df_titanic['LogFare'] = np.log1p(df_titanic['Fare'])`\n",
    "    - Uses NumPy (`np.log1p`) to apply the log to all 'Fare' values at once (vectorized means super fast!).\n",
    "    - `log1p` adds 1 first (e.g., $7 becomes 8, then logs it) to avoid breaking with $0 fares.\n",
    "    - Creates a new column 'LogFare' with the smoothed numbers.\n",
    "  - `print(\"\\nStep 8b: Log of Fare (first 5):\")`\n",
    "    - Lets us know the new column is ready and shows the first five examples.\n",
    "  - `print(df_titanic[['Fare', 'LogFare']].head())`\n",
    "    - Displays a table with the original 'Fare' and new 'LogFare' for the first five passengers, like comparing the old shout to the new whisper!\n",
    "\n",
    "- **What It Means**: \n",
    "  - Before: 'Fare' had big jumps (e.g., $7 to $71). Now, 'LogFare' makes them closer (e.g., 2 to 4), so our model won’t favor the big fares.\n",
    "  - **Analogy**: It’s like a DJ softening a loud song ($71) to match a quiet one ($7) on the same playlist, making the party vibe smooth!\n",
    "- **Memory Trick Practice**: Say “Log = Level!” and imagine turning a volume knob to balance fares. Check the output to see the new whisper levels.\n",
    "\n",
    "## Explaining the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8dc37938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 8c: Optimized 'AgeGroup' and 'FareCategory' to category type.\n"
     ]
    }
   ],
   "source": [
    "# Optimize memory by converting 'AgeGroup' and 'FareCategory' to category type\n",
    "df_titanic['AgeGroup'] = df_titanic['AgeGroup'].astype('category')\n",
    "df_titanic['FareCategory'] = df_titanic['FareCategory'].astype('category')\n",
    "print(\"\\nStep 8c: Optimized 'AgeGroup' and 'FareCategory' to category type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2575a5ed",
   "metadata": {},
   "source": [
    "# Understanding Step 8c: Optimizing Memory with Category Type\n",
    "\n",
    "This step is like packing a suitcase smarter to save space! We’re changing 'AgeGroup' and 'FareCategory' in the Titanic dataset into a special format to use less computer memory, making our work faster. Let’s break down the code, learn why this helps, and practice remembering it with a fun trick.\n",
    "\n",
    "## What is Memory Optimization with Category Type?\n",
    "- **Definition**: Converting columns like 'AgeGroup' (e.g., 'Child', 'Adult') or 'FareCategory' (e.g., 'Cheap', 'Expensive') to 'category' type tells the computer to store them efficiently, like using shortcuts instead of writing everything out.\n",
    "- **Why to Use**: \n",
    "  - Saves memory when we have lots of repeated words (e.g., 'Adult' for many passengers), so our program runs quicker.\n",
    "  - **Analogy**: It’s like using a sticker sheet with 'Child,' 'Adult,' etc., instead of writing those words on every photo label—less ink, same info!\n",
    "- **What It Does**: Turns text categories into a compact code behind the scenes, reducing the file size.\n",
    "- **When to Use**: \n",
    "  - Use this when you have columns with a few repeated categories (e.g., 'Sex' or 'AgeGroup') and want to speed up your work, especially for big datasets or models.\n",
    "  - **Analogy**: Use it when packing for a trip with lots of the same clothes—use tags like 'T-shirt' instead of listing each one!\n",
    "- **Memory Trick**: Think “Category = Compact!”—imagine shrinking a big word list into tiny stickers. Say “Category = Compact!” a few times to stick it in your mind!\n",
    "- **Why It Matters**: As a data scientist, you’ll optimize data to handle large projects faster, a key skill for jobs in tech or research!\n",
    "\n",
    "## Breaking Down the Code\n",
    "- **Code**: \n",
    "  - `# Optimize memory by converting 'AgeGroup' and 'FareCategory' to category type`\n",
    "    - Tells us we’re making these columns use less space for better performance.\n",
    "  - `df_titanic['AgeGroup'] = df_titanic['AgeGroup'].astype('category')`\n",
    "    - Changes 'AgeGroup' (e.g., 'Child', 'Teen') into a category type, like swapping long labels for stickers.\n",
    "  - `df_titanic['FareCategory'] = df_titanic['FareCategory'].astype('category')`\n",
    "    - Does the same for 'FareCategory' (e.g., 'Cheap', 'Moderate'), packing it efficiently.\n",
    "  - `print(\"\\nStep 8c: Optimized 'AgeGroup' and 'FareCategory' to category type.\")`\n",
    "    - Lets us know the change is done, like checking our suitcase is lighter!\n",
    "\n",
    "- **What It Means**: \n",
    "  - Before: 'AgeGroup' and 'FareCategory' were stored as full words for each passenger. Now, they’re coded as shortcuts, saving space.\n",
    "  - **Analogy**: It’s like a travel agent swapping a heavy book of labels for a small sticker sheet, making your luggage easier to carry!\n",
    "- **Memory Trick Practice**: Say “Category = Compact!” and imagine sticking 'Child' or 'Cheap' onto a photo with a tiny sticker. Check the next steps to see the savings in action.\n",
    "- **Why It’s Useful**: This speeds up our model when predicting survival, especially with lots of passengers!\n",
    "\n",
    "## What’s Next?\n",
    "- We’ll explore more ways to make our data work better and get ready for predictions. Keep packing smart to learn more!\n",
    "- *Note*: This dataset has historical gaps, which we’ll handle fairly in Week 4. For now, enjoy making your data lighter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32c61132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 9a: Ticket Adjustment DataFrame (first 5):\n",
      "             Ticket  Adjustment\n",
      "0         A/5 21171    7.015100\n",
      "1          PC 17599   -7.115407\n",
      "2  STON/O2. 3101282   -5.268915\n",
      "3            113803    8.259056\n",
      "4            373450    7.132332\n"
     ]
    }
   ],
   "source": [
    "# --- Section 9: Merging and Joining ---\n",
    "# Create a small DataFrame with ticket adjustments for merging demonstration\n",
    "ticket_adjustment = pd.DataFrame({\n",
    "    'Ticket': df_titanic['Ticket'].unique(),\n",
    "    'Adjustment': np.random.uniform(-10, 10, size=len(df_titanic['Ticket'].unique()))\n",
    "})\n",
    "print(\"\\nStep 9a: Ticket Adjustment DataFrame (first 5):\")\n",
    "print(ticket_adjustment.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a27ee8",
   "metadata": {},
   "source": [
    "# Understanding Step 9a: Creating a Ticket Adjustment DataFrame\n",
    "\n",
    "This step is like adding a bonus gift list to our passenger party plan! We’re making a new table with ticket adjustments to show how we can combine it with our Titanic data later. Let’s break down the code, learn what merging is about, and practice remembering it with a fun trick.\n",
    "\n",
    "## What is Merging and Joining?\n",
    "- **Definition**: Merging and joining is like matching two lists—our passenger data and a new adjustment list—to add extra info, making our story richer.\n",
    "- **Simple Analogy**: Imagine you’re planning a party and have a guest list. You get a second list with gift amounts for each guest. Merging is like pairing the guest list with the gift list to see who gets what!\n",
    "- **Memory Trick**: Think “Merge = Match!”—picture sticking two friend groups’ name tags together. Say “Merge = Match!” a few times to get it stuck in your head!\n",
    "- **Why It Matters**: As a data scientist, you’ll merge data to add details (e.g., price changes), a key skill for jobs in travel or finance!\n",
    "\n",
    "## Breaking Down the Code\n",
    "- **Code**: \n",
    "  - `# Create a small DataFrame with ticket adjustments for merging demonstration`\n",
    "    - Tells us we’re building a mini-table to practice adding adjustments.\n",
    "  - `ticket_adjustment = pd.DataFrame({`\n",
    "    - Starts a new table using Pandas (`pd.DataFrame`).\n",
    "  - `'Ticket': df_titanic['Ticket'].unique(),`\n",
    "    - Lists all unique ticket numbers from our passenger data, like collecting every party invitation.\n",
    "  - `'Adjustment': np.random.uniform(-10, 10, size=len(df_titanic['Ticket'].unique()))`\n",
    "    - Adds random adjustment numbers between -10 and 10 for each ticket, like picking surprise gift amounts.\n",
    "    - `np.random.uniform` picks these numbers, and `size` matches the ticket count.\n",
    "  - `})`\n",
    "    - Closes the table creation.\n",
    "  - `print(\"\\nStep 9a: Ticket Adjustment DataFrame (first 5):\")`\n",
    "    - Lets us know the new table is ready and shows the first five rows.\n",
    "  - `print(ticket_adjustment.head())`\n",
    "    - Displays the top five entries, like peeking at the first five gift tags!\n",
    "\n",
    "- **What It Means**: \n",
    "  - We made a new list pairing each ticket (e.g., 'A/5 21171') with a random adjustment (e.g., 7.01), like adding a bonus to some party gifts.\n",
    "  - **Analogy**: It’s like a party planner making a side list of extra treats for each invitation, ready to match it with the main guest list!\n",
    "- **Memory Trick Practice**: Say “Merge = Match!” and imagine sticking a gift tag next to each invitation. Check the output to see the matches and build that muscle memory.\n",
    "- **Why It’s Useful**: This extra info can help adjust fares or predict survival, making our model smarter!\n",
    "\n",
    "## Explaining the Results\n",
    "- **Output**: `Step 9a: Ticket Adjustment DataFrame (first 5):`\n",
    "  - `Ticket         Adjustment`\n",
    "  - `0         A/5 21171    7.015100`\n",
    "  - `1          PC 17599   -7.115407`\n",
    "  - `2  STON/O2. 3101282   -5.268915`\n",
    "  - `3            113803    8.259056`\n",
    "  - `4            373450    7.132332`\n",
    "- **What It Means**: \n",
    "  - **Ticket**: Unique ticket numbers from the Titanic, like party invitations (e.g., 'A/5 21171').\n",
    "  - **Adjustment**: Random numbers between -10 and 10, like bonus gifts (e.g., 7.01 means +$7.01, -7.11 means -$7.11).\n",
    "  - **Analogy**: It’s like seeing a list where 'A/5 21171' gets a $7.01 treat, 'PC 17599' loses $7.11, and so on—ready to add to the party plan!\n",
    "- **Why It Works**: These adjustments can tweak fares later, helping us analyze if money changes survival chances.\n",
    "\n",
    "## What’s Next?\n",
    "- We’ll match this list with our passenger data and adjust fares. Keep matching those tags to learn more!\n",
    "- *Note*: This dataset has historical gaps, which we’ll handle fairly in Week 4. For now, enjoy building your extra list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc967c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 9b: Merged DataFrame (first 5):\n",
      "             Ticket  Adjustment\n",
      "0         A/5 21171    7.015100\n",
      "1          PC 17599   -7.115407\n",
      "2  STON/O2. 3101282   -5.268915\n",
      "3            113803    8.259056\n",
      "4            373450    7.132332\n"
     ]
    }
   ],
   "source": [
    "# Merge ticket adjustments with the main DataFrame\n",
    "df_titanic = pd.merge(df_titanic, ticket_adjustment, on='Ticket', how='left')\n",
    "print(\"\\nStep 9b: Merged DataFrame (first 5):\")\n",
    "print(df_titanic[['Ticket', 'Adjustment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb805ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 9c: Adjusted Fare (first 5):\n",
      "      Fare  Adjustment  AdjustedFare\n",
      "0   7.2500    7.015100     14.265100\n",
      "1  71.2833   -7.115407     64.167893\n",
      "2   7.9250   -5.268915      2.656085\n",
      "3  53.1000    8.259056     61.359056\n",
      "4   8.0500    7.132332     15.182332\n"
     ]
    }
   ],
   "source": [
    "# Calculate adjusted fare by adding the adjustment\n",
    "df_titanic['AdjustedFare'] = df_titanic['Fare'] + df_titanic['Adjustment']\n",
    "print(\"\\nStep 9c: Adjusted Fare (first 5):\")\n",
    "print(df_titanic[['Fare', 'Adjustment', 'AdjustedFare']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c19812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged with custom DataFrame on Name:\n",
      "                                                Name  CustomValue\n",
      "0                            Braund, Mr. Owen Harris     0.320761\n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...     0.333112\n",
      "2                             Heikkinen, Miss. Laina     0.093483\n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)     0.949955\n",
      "4                           Allen, Mr. William Henry     0.991678\n"
     ]
    }
   ],
   "source": [
    "# Interactive: Ask students to merge with a custom DataFrame\n",
    "custom_data = input(\"Step 9d: Enter a column to merge with (e.g., 'Name'), or skip: \")\n",
    "if custom_data in df_titanic.columns:\n",
    "    custom_df = pd.DataFrame({custom_data: df_titanic[custom_data].unique(), 'CustomValue': np.random.rand(len(df_titanic[custom_data].unique()))})\n",
    "    df_titanic = pd.merge(df_titanic, custom_df, on=custom_data, how='left')\n",
    "    print(f\"\\nMerged with custom DataFrame on {custom_data}:\")\n",
    "    print(df_titanic[[custom_data, 'CustomValue']].head())\n",
    "else:\n",
    "    print(\"Skipping custom merge or invalid column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6e93b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 10a: Features selected for ML: ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'Sex_male', 'Embarked_Q', 'Embarked_S', 'AgeGroup', 'Fare_scaled', 'Age_standardized']\n",
      "Step 10b: Target variable: Survived\n"
     ]
    }
   ],
   "source": [
    "# --- Section 10: Preparing Data for Machine Learning ---\n",
    "# Select numerical and encoded features for ML model training\n",
    "df_titanic['Age_standardized'] = (df_titanic['Age'] - df_titanic['Age'].mean()) / df_titanic['Age'].std()\n",
    "features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'Sex_male', 'Embarked_Q', 'Embarked_S', 'AgeGroup', 'Fare_scaled', 'Age_standardized']\n",
    "X = df_titanic[features]\n",
    "y = df_titanic['Survived']\n",
    "print(\"\\nStep 10a: Features selected for ML:\", features)\n",
    "print(\"Step 10b: Target variable:\", y.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b304bb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid action or feature. Features unchanged: ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'Sex_male', 'Embarked_Q', 'Embarked_S', 'AgeGroup', 'Fare_scaled', 'Age_standardized']\n"
     ]
    }
   ],
   "source": [
    "# Interactive: Ask students to add or remove a feature\n",
    "feature_action = input(\"Step 10c: Add or remove a feature? (add/remove, then feature name, e.g., 'add AgeGroup'): \").split()\n",
    "if feature_action[0].lower() == 'add' and feature_action[1] in df_titanic.columns and feature_action[1] not in features:\n",
    "    features.append(feature_action[1])\n",
    "    X = df_titanic[features]\n",
    "    print(f\"\\nAdded {feature_action[1]} to features. New features:\", features)\n",
    "elif feature_action[0].lower() == 'remove' and feature_action[1] in features:\n",
    "    features.remove(feature_action[1])\n",
    "    X = df_titanic[features]\n",
    "    print(f\"\\nRemoved {feature_action[1]} from features. New features:\", features)\n",
    "else:\n",
    "    print(\"Invalid action or feature. Features unchanged:\", features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
