{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20414eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbb49bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Reading the File\n",
    "# Load the Boston Housing Dataset from Scikit-learn\n",
    "\n",
    "boston = fetch_openml(name=\"boston\", version=1)\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['MEDV'] = boston.target  # Median house value in $1000s\n",
    "print(\"Step 1: Dataset loaded with\", df.shape[0], \"houses and\", df.shape[1], \"features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41101fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Exploratory Data Analysis (EDA)\n",
    "pd.set_option('display.width', 1000)\n",
    "print(\"\\nStep 2: EDA - First few rows of the dataset:\")\n",
    "print(df.head())\n",
    "print (\"\\nSummary statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc0361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Data Cleaning\n",
    "# Check for missing values and handle them (none in this dataset, but shown as example)\n",
    "print(\"\\nStep 3: Checking for missing values:\")\n",
    "print(df.isnull().sum())\n",
    "# If missing, use: df.fillna(df.mean(), inplace=True) - not needed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c2b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Feature Engineering and Selecting Final Features\n",
    "# Create a new feature: rooms per household\n",
    "df['RM_PER_HOUSEHOLD'] = df['RM'] / df['PTRATIO']  # Rooms divided by pupil-teacher ratio\n",
    "# Select final features: RM (rooms) and RM_PER_HOUSEHOLD as predictors\n",
    "selected_features = ['RM', 'RM_PER_HOUSEHOLD']\n",
    "X = df[selected_features]\n",
    "y = df['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fdb9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Correlation Matrix\n",
    "print(\"\\nStep 5: Correlation Matrix:\")\n",
    "correlation_matrix = df[['MEDV', 'RM', 'RM_PER_HOUSEHOLD']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f6fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Create Histograms of Various Features\n",
    "print(\"\\nStep 6: Histograms of Features:\")\n",
    "df[['MEDV', 'RM', 'RM_PER_HOUSEHOLD']].hist(bins=20, figsize=(10, 6))\n",
    "plt.suptitle(\"Histograms of Median Value, Rooms, and Rooms per Household\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f820e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: How to Create Training, Test, and Validation Data\n",
    "# Split into training (70%), test (15%), and validation (15%)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1765, random_state=42)  # 0.15/(0.85) â‰ˆ 0.1765\n",
    "print(\"\\nStep 7: Data Split - Training:\", X_train.shape, \"Test:\", X_test.shape, \"Validation:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c49ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()  # Display first few rows of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d5284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Model Training and Selection\n",
    "# Train Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Train Bagging (Random Forest)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)  # 100 trees\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Train Boosting (Gradient Boosting)\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nStep 8: Models trained with features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a064cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Model Performance Metrics and Graphs\n",
    "# Predict for all models\n",
    "lr_test_pred = lr_model.predict(X_test)\n",
    "lr_val_pred = lr_model.predict(X_val)\n",
    "rf_test_pred = rf_model.predict(X_test)\n",
    "rf_val_pred = rf_model.predict(X_val)\n",
    "gb_test_pred = gb_model.predict(X_test)\n",
    "gb_val_pred = gb_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65447b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for Linear Regression\n",
    "lr_test_mse = mean_squared_error(y_test, lr_test_pred)\n",
    "lr_val_mse = mean_squared_error(y_val, lr_val_pred)\n",
    "lr_test_r2 = r2_score(y_test, lr_test_pred)\n",
    "lr_val_r2 = r2_score(y_val, lr_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for Random Forest (Bagging)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_test_pred)\n",
    "rf_val_mse = mean_squared_error(y_val, rf_val_pred)\n",
    "rf_test_r2 = r2_score(y_test, rf_test_pred)\n",
    "rf_val_r2 = r2_score(y_val, rf_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f16d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for Gradient Boosting (Boosting)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_test_pred)\n",
    "gb_val_mse = mean_squared_error(y_val, gb_val_pred)\n",
    "gb_test_r2 = r2_score(y_test, gb_test_pred)\n",
    "gb_val_r2 = r2_score(y_val, gb_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7af3682",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStep 9: Performance Metrics:\")\n",
    "print(\"Linear Regression - Test MSE: {:.2f}, R-squared: {:.2f}\".format(lr_test_mse, lr_test_r2))\n",
    "print(\"Linear Regression - Validation MSE: {:.2f}, R-squared: {:.2f}\".format(lr_val_mse, lr_val_r2))\n",
    "print(\"Random Forest (Bagging) - Test MSE: {:.2f}, R-squared: {:.2f}\".format(rf_test_mse, rf_test_r2))\n",
    "print(\"Random Forest (Bagging) - Validation MSE: {:.2f}, R-squared: {:.2f}\".format(rf_val_mse, rf_val_r2))\n",
    "print(\"Gradient Boosting (Boosting) - Test MSE: {:.2f}, R-squared: {:.2f}\".format(gb_test_mse, gb_test_r2))\n",
    "print(\"Gradient Boosting (Boosting) - Validation MSE: {:.2f}, R-squared: {:.2f}\".format(gb_val_mse, gb_val_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b198df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs. actual values for all models\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(y_test, lr_test_pred, color='blue', label='Linear Regression Test')\n",
    "plt.scatter(y_val, lr_val_pred, color='lightblue', label='Linear Regression Validation')\n",
    "# plt.scatter(y_test, rf_test_pred, color='green', label='Random Forest Test')\n",
    "# plt.scatter(y_val, rf_val_pred, color='lightgreen', label='Random Forest Validation')\n",
    "# plt.scatter(y_test, gb_test_pred, color='red', label='Gradient Boosting Test')\n",
    "# plt.scatter(y_val, gb_val_pred, color='pink', label='Gradient Boosting Validation')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "plt.xlabel(\"Actual Median Value ($1000s)\")\n",
    "plt.ylabel(\"Predicted Median Value ($1000s)\")\n",
    "plt.title(\"Actual vs. Predicted Values (Linear Regression vs. Ensembles)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Interactive Prediction for Given Values\n",
    "print(\"\\nInteractive Prediction: Enter values for RM and RM_PER_HOUSEHOLD to predict MEDV\")\n",
    "while True:\n",
    "    try:\n",
    "        rm = float(input(\"Enter average number of rooms (RM, e.g., 6.0): \"))\n",
    "        rm_per_household = float(input(\"Enter rooms per household (RM_PER_HOUSEHOLD, e.g., 0.5): \"))\n",
    "        new_data = np.array([[rm, rm_per_household]])\n",
    "\n",
    "        # Predict with all models\n",
    "        lr_pred = lr_model.predict(new_data)[0]\n",
    "        rf_pred = rf_model.predict(new_data)[0]\n",
    "        gb_pred = gb_model.predict(new_data)[0]\n",
    "\n",
    "        print(f\"Linear Regression Predicted Median Value: ${lr_pred:.2f}K\")\n",
    "        print(f\"Random Forest (Bagging) Predicted Median Value: ${rf_pred:.2f}K\")\n",
    "        print(f\"Gradient Boosting (Boosting) Predicted Median Value: ${gb_pred:.2f}K\")\n",
    "\n",
    "        # Compare with actual value (if available in dataset)\n",
    "        closest_row = df.iloc[(df['RM'] - rm).abs().idxmin()]\n",
    "        actual_value = closest_row['MEDV'] / 1000  # Convert to $1000s\n",
    "        print(f\"Closest Actual Value: ${actual_value:.2f}K (based on RM={closest_row['RM']:.2f})\")\n",
    "        print(f\"Differences: LR: ${(lr_pred - actual_value):.2f}K, RF: ${(rf_pred - actual_value):.2f}K, GB: ${(gb_pred - actual_value):.2f}K\")\n",
    "\n",
    "        # Example of future value prediction with 10% increase\n",
    "        future_rm = rm * 1.1\n",
    "        future_rm_per_household = rm_per_household * 1.1\n",
    "        future_data = np.array([[future_rm, future_rm_per_household]])\n",
    "        lr_future = lr_model.predict(future_data)[0]\n",
    "        rf_future = rf_model.predict(future_data)[0]\n",
    "        gb_future = gb_model.predict(future_data)[0]\n",
    "        print(f\"Expected Future Value (10% more rooms) - LR: ${lr_future:.2f}K, RF: ${rf_future:.2f}K, GB: ${gb_future:.2f}K\")\n",
    "\n",
    "        if input(\"Continue predicting? (yes/no): \").lower() != 'yes':\n",
    "            break\n",
    "    except ValueError:\n",
    "        print(\"Please enter valid numbers!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
